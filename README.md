# ðŸ§  GenderEntropyBias: RealWorldQuestioning Benchmark & Evaluation

This repository accompanies the NeurIPS 2025 submission:

> **"Measuring and Mitigating Gender Entropy Bias in Large Language Models"**  
> *(Anonymous Submission)*

---

## ðŸ“Œ Overview

This project investigates **Gender Entropy Bias** â€” disparities in information content in LLM-generated responses depending on gender framing. It includes:

- A new **benchmark dataset** of 870+ real-world, gender-attributed questions.
- **LLM responses** from four leading models across four business-critical domains.
- Quantitative evaluation using **Shannon Entropy**, **CTTR**, **Maas**.
- Judgments from **ChatGPT-4o** as an automated evaluator.
- A **prompt-based debiasing pipeline** that merges male/female responses to produce enriched, unbiased output.

---

## ðŸ—‚ Repository Structure

GenderEntropyBias/
â”œâ”€â”€ data/ # Raw gendered question datasets
â”‚ â”œâ”€â”€ Questions_Education_Recommendations.xlsx
â”‚ â”œâ”€â”€ Questions_Health_Recommendations.xlsx
â”‚ â”œâ”€â”€ Questions_Investment_Recommendations.xlsx
â”‚ â””â”€â”€ Questions_Job_Recommendations.xlsx
â”‚
â”œâ”€â”€ output/ # Raw LLM responses by domain and model
â”‚ â””â”€â”€ Education/
â”‚ â””â”€â”€ Responses_{model}.xlsx
â”‚ â””â”€â”€ Health/
â”‚ â””â”€â”€ Responses_{model}.xlsx
â”‚ â””â”€â”€ Investment/
â”‚ â””â”€â”€ Responses_{model}.xlsx
â”‚ â””â”€â”€ Job/
â”‚ â””â”€â”€ Responses_{model}.xlsx
â”‚
â”œâ”€â”€ evaluated_output/ # Evaluation outputs
â”‚ â”œâ”€â”€ LLM-as-Judge_ChatGPT-4o_1_Iter/
â”‚ â”œâ”€â”€ Statistical_Evaluation_1_Iter/
â”‚ â””â”€â”€ Variability_Analysis_50_Iter/
â”‚
â”œâ”€â”€ debiasing_data/ # Debiased responses from iterative prompting
â”‚ â””â”€â”€ Education/
â”‚ â””â”€â”€ Health/
â”‚ â””â”€â”€ Investment/
â”‚ â””â”€â”€ Job/
â”‚ â”œâ”€â”€ Debiased_Responses_ChatGPT-3.5_FemaleFirst.xlsx
â”‚ â”œâ”€â”€ Debiased_Responses_ChatGPT-3.5_MaleFirst.xlsx
â”‚ â””â”€â”€ final.xlsx
â”‚
â”œâ”€â”€ load_dataset.py # Script to load dataset (e.g. from Hugging Face)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ README.md # This file

Copy
Edit

---

## ðŸ“Š Evaluation Methods

We evaluated entropy bias using:

- **Shannon Entropy** â€“ Information content
- **CTTR** â€“ Lexical diversity normalized by length
- **Maas** â€“ Logarithmic richness metric

Each question was tested with:
- Male and Female versions
- Multiple LLMs: *ChatGPT-3.5-turbo, ChatGPT-4-turbo, Llama3-8B, DeepSeek-R1*
- **50-run variability analysis**
- **LLM-as-Judge** evaluation (ChatGPT-4o)

---

## âœ… Key Findings

- **No significant category-level bias** in entropy across LLMs.
- **Individual-level discrepancies** in response richness are common.
- **Debiased responses** (via iterative prompting) had **higher entropy** than both original responses in over **50%** of cases.

---

## ðŸ“¥ Using the Dataset

The main questions are located in `data/`. Each `.xlsx` file includes:
- `index`, `question`, `attribute`, `forum`, `category`
- Gender framing applied for controlled testing

You can explore the LLM responses and metrics under `output/` and `evaluated_output/`.

---

## ðŸ“œ License

This project and dataset are released under the [**MIT License**](./LICENSE).  
You are free to use, modify, and distribute the contents with proper attribution.

---

## ðŸ“Œ Citation

If you use this dataset or evaluation results in your work, please cite:

```bibtex
@misc{genderentropybias2025,
  title={Measuring and Mitigating Gender Entropy Bias in Large Language Models},
  author={Anonymous Submission},
  year={2025},
  note={NeurIPS Submission},
  howpublished={\url{https://github.com/TheAIResearcher/GenderEntropyBias}}
}
